{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SplitControlsToSets\n",
    "### Splits each control dataset into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../Data/Datasets/\"\n",
    "lr_path = f\"{data_dir}/LR/\"\n",
    "lnr_path = f\"{data_dir}/LNR/\"\n",
    "lgr_path = f\"{data_dir}/LGR/\"\n",
    "lgnr_path = f\"{data_dir}/LGNR/\"\n",
    "\n",
    "path_list = [lr_path, lnr_path, lgr_path, lgnr_path]\n",
    "file_list = [\"lr.fa\", \"lnr.fa\", \"lgr.fa\", \"lgnr.fa\"]\n",
    "\n",
    "for path in path_list:\n",
    "    assert os.path.exists(path), f\"Path {path} does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "### MAKE SURE THESE ARE THE SAME AS THE ONES IN FantomData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "valid_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the control datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, file_name in zip(path_list, file_list):\n",
    "\n",
    "    # Get paths\n",
    "    fasta_path = f\"{path}/{file_name}\"\n",
    "    train_path = f\"{path}/train_{file_name}\"\n",
    "    valid_path = f\"{path}/valid_{file_name}\"\n",
    "    test_path = f\"{path}/test_{file_name}\"\n",
    "\n",
    "    # Read in fasta file\n",
    "    seq_list = list(SeqIO.parse(fasta_path, 'fasta'))\n",
    "\n",
    "    # Filter out sequences longer than max_len\n",
    "    keep_list = []\n",
    "    for rec in seq_list:\n",
    "        if len(str(rec.seq)) <= max_len:\n",
    "            keep_list.append(rec)\n",
    "\n",
    "    # Get cutoffs (percentages) for train and valid (test is the rest)\n",
    "    train_cutoff = int(len(keep_list) * train_ratio)\n",
    "    valid_cutoff = int(len(keep_list) * (train_ratio + valid_ratio))\n",
    "\n",
    "    # cut up the list into train, valid, and test\n",
    "    train_list = keep_list[:train_cutoff]\n",
    "    valid_list = keep_list[train_cutoff:valid_cutoff]\n",
    "    test_list = keep_list[valid_cutoff:]\n",
    "\n",
    "    # Write out the files\n",
    "    SeqIO.write(train_list, train_path, 'fasta')\n",
    "    SeqIO.write(valid_list, valid_path, 'fasta')\n",
    "    SeqIO.write(test_list, test_path, 'fasta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
